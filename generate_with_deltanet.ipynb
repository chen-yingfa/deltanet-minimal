{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeltaNetConfig(vocab_size=32000, hidden_size=2048, initializer_range=0.02, hidden_ratio=4, expand_k=1, expand_v=1, num_heads=16, num_hidden_layers=24, tie_word_embeddings=False, conv_size=4, norm_eps=1e-06, pad_token_id=2, eos_token_id=2, bos_token_id=1, chunk_size=32)\n",
      "DeltaNetForCausalLM(\n",
      "  (model): DeltaNetModel(\n",
      "    (embeddings): Embedding(32000, 2048, padding_idx=2)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x DeltaNetLayer(\n",
      "        (attn_norm): RMSNorm()\n",
      "        (attn): DeltaNet(\n",
      "          (k_conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048, bias=False)\n",
      "          (v_conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048, bias=False)\n",
      "          (q_conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048, bias=False)\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (b_proj): Linear(in_features=2048, out_features=16, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (o_norm): RMSNorm()\n",
      "        )\n",
      "        (mlp_norm): RMSNorm()\n",
      "        (mlp): MLP(\n",
      "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
      ")\n",
      "Loading checkpoint from model.safetensors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from deltanet import DeltaNetForCausalLM, DeltaNetConfig\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "config_path = \"configs/1.3b.json\"\n",
    "ckpt_path = \"model.safetensors\"\n",
    "tok_path = 'fla-hub/delta_net-1.3B-100B'\n",
    "device = 'mps'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./tokenizer')\n",
    "# tokenizer.save_pretrained('tokenizer')\n",
    "config = DeltaNetConfig.from_pretrained(config_path)\n",
    "print(config)\n",
    "model = DeltaNetForCausalLM(config=config).to(device, dtype=torch.bfloat16)\n",
    "model.eval()\n",
    "print(model)\n",
    "print(f\"Loading checkpoint from {ckpt_path}\")\n",
    "state_dict = load_file(ckpt_path)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== prompt ======\n",
      "My name is\n",
      "====================\n",
      "====== output ======\n",
      "['<s> My name is Katie and I am a 20 year old student at the University of North Carolina at Chap']\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "prompt = 'My name is'\n",
    "input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "print('====== prompt ======')\n",
    "print(prompt)\n",
    "print('====================')\n",
    "outputs = model.generate(input_ids, max_new_tokens=20)\n",
    "output_text = tokenizer.batch_decode(outputs)\n",
    "print('====== output ======')\n",
    "print(output_text)\n",
    "print('====================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
